{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# MACHINE LEARNING ASSIGNMENT"
      ],
      "metadata": {
        "id": "JGvuR2TbDvXc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.  Explain the differences between AI, ML, Deep Learning (DL), and Data\n",
        "Science (DS).\n",
        "\n",
        "-> Artificial Intelligence (AI)\n",
        "\n",
        "Broad field concerned with making machines/systems that can perform tasks which normally require human intelligence: reasoning, perception, decision making, planning, natural language understanding, etc.\n",
        "\n",
        "\n",
        "Not limited to learning from data; might include rule-based systems, heuristics, expert systems.\n",
        "\n",
        "\n",
        "Machine Learning (ML)\n",
        "\n",
        "Subset of AI. The set of techniques where systems learn from data (rather than being explicitly programmed for every case).\n",
        "\n",
        "\n",
        "It involves creating algorithms/models that improve with more data/experience. Methods include supervised learning, unsupervised learning, reinforcement learning.\n",
        "\n",
        "\n",
        "Deep Learning (DL)\n",
        "\n",
        "Subset of machine learning. Uses neural networks with many layers (“deep” networks) to automatically learn representations/features from data.\n",
        "\n",
        "\n",
        "Particularly useful for large amounts of unstructured data (images, audio, text), where feature engineering by hand is difficult.\n",
        "\n",
        "\n",
        "Data Science (DS)\n",
        "\n",
        "More interdisciplinary. Involves collecting, cleaning, processing, analyzing, visualizing data, and using it to draw insights, make decisions, build predictive models.\n",
        "\n",
        "DS uses tools & techniques from statistics, ML, sometimes DL, domain knowledge, data visualization, etc. It’s not just about “making smart machines,” but about extracting useful insights from data."
      ],
      "metadata": {
        "id": "1rqJWu50D-LU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. What are the types of machine learning? Describe each with one\n",
        "real-world example.\n",
        "\n",
        "-> Supervised Learning\n",
        "\n",
        "In supervised learning, the system is given input data along with the correct output (“labels”) during training. The model learns to map inputs to outputs, so that when new, unseen inputs come it can predict the correct output. Problems in supervised learning include classification (where output is a category) and regression (where output is a continuous value).\n",
        "\n",
        "\n",
        "Real-world example:\n",
        "Predicting house prices. A model is trained on data with features like “square footage”, “number of bedrooms”, “location” and with the correct selling price. After training, given a new house, the model predicts its price.\n",
        "\n",
        "\n",
        "Unsupervised Learning\n",
        "\n",
        "Here, the model is given data without any explicit labels. It seeks to discover underlying structure: grouping similar data points together, finding patterns, identifying density or anomalies, reducing dimensions, etc. The model doesn’t know ahead of time what the correct output should be.\n",
        "\n",
        "\n",
        "Real-world example:\n",
        "Customer segmentation in marketing: A company might have purchase history data for many customers, but no labels saying “this customer is VIP”, “this one is budget-buyer”, etc. Using unsupervised clustering techniques, the company can group customers based on their behavior, then tailor marketing strategies to each group.\n",
        "\n",
        "\n",
        "Semi-Supervised Learning\n",
        "\n",
        "This is a mix of supervised and unsupervised. In many practical scenarios, obtaining labels is expensive or time-consuming, but unlabeled data is abundant. Semi-supervised methods use a small amount of labeled data together with a larger pool of unlabeled data to improve learning.\n",
        "\n",
        "\n",
        "Real-world example:\n",
        "Image recognition for medical imagery: Suppose only a few medical images are annotated (e.g. showing specific conditions) but many more are not. A semi-supervised approach can use the annotated ones to guide learning, and unlabeled ones to help the model learn features or structure, improving performance while saving on labeling cost.\n",
        "\n",
        "Self-Supervised Learning\n",
        "\n",
        "A subtype of unsupervised / semi-supervised learning, where the system automatically creates “pseudo-labels” from the data itself. Essentially, part of the data is used to predict another part, which gives a supervisory signal without manual labeling. Widely used in natural language processing (e.g. language models) and computer vision.\n",
        "\n",
        "Real-world example:\n",
        "Predicting the next word in a sentence: Given parts of text, the model tries to predict what comes next. This lets huge text corpora be used to train powerful language models without needing human-labels for “this is correct label”. Another example is masked image modeling in vision (e.g. remove part of image and predict what’s missing).\n",
        "\n",
        "Reinforcement Learning\n",
        "\n",
        "In reinforcement learning (RL), an agent interacts with an environment, takes actions, and receives feedback in the form of rewards or penalties. The agent’s objective is to learn a policy (strategy) that maximizes cumulative reward over time. RL does not require labeled input/output pairs; instead it learns via trial and error.\n",
        "\n",
        "\n",
        "Real-world example:\n",
        "Training a robot to walk or a self-driving car to navigate. The robot tries out movements, gets rewarded for moving forward without falling, penalized for falling. Over many trials, it learns actions that maintain balance and move effectively. Also, video games (e.g. AlphaGo, or agents playing Atari games) use RL to learn strategies."
      ],
      "metadata": {
        "id": "md0aDbS1Ecmc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Define overfitting, underfitting, and the bias-variance tradeoff in machine\n",
        "learning.\n",
        "\n",
        "-> Underfitting\n",
        "\n",
        "What it means: A model underfits when it is too simple to capture the underlying pattern in the data. It fails to learn enough; it has not “learned” from the data’s structure.\n",
        "\n",
        "What happens in practice: Both the training error and test (validation) error are large. The model performs poorly even on the data it was trained on.\n",
        "\n",
        "Why it happens: Possible causes include using a model that is too simplistic (e.g. linear model when relationship is non-linear), having too few features, insufficient training time, too much regularization, etc.\n",
        "\n",
        "Real-world clue: Imagine trying to predict house prices but using only one feature (say, size), ignoring location, number of bedrooms etc. The model will miss many relevant factors and hence underperform.\n",
        "\n",
        "Overfitting\n",
        "\n",
        "What it means: A model overfits when it is too complex, so it starts to learn not only the true underlying pattern but also the noise, peculiarities, or quirks of the specific training data. It “memorizes” rather than generalizes.\n",
        "\n",
        "What happens in practice: Very low error on training data but much higher error on unseen (test/validation) data. The model performs well in training but generalizes poorly.\n",
        "\n",
        "\n",
        "Why it happens: Using overly complex models (e.g. very deep neural networks, very high-degree polynomials), insufficient data, noisy data, too little regularization, etc.\n",
        "\n",
        "\n",
        "Real-world clue: Say you fit a polynomial of degree 10 to just 20 data points. The curve might pass exactly through all points, but on new data it will swing wildly and make wrong predictions. Or in classification, a decision tree that splits until each leaf has just one example may overfit.\n",
        "\n",
        "Bias-Variance Trade-off\n",
        "\n",
        "This concept helps understand and balance between underfitting and overfitting.\n",
        "\n",
        "Bias: Error due to overly strong assumptions in the model. A high bias model is too simple and misses true relationships between features and the outcome. → underfitting.\n",
        "\n",
        "\n",
        "Variance: Error due to sensitivity to fluctuations in the training data. A high variance model fits training data “too well” (including noise), so its predictions change a lot if we used a different training set. → overfitting.\n",
        "\n",
        "\n",
        "Total Error (on unseen data) is roughly the sum of:\n",
        "\n",
        "Bias² (squared bias)\n",
        "\n",
        "Variance\n",
        "\n",
        "Irreducible error (noise) — the error intrinsic to the problem, which no model can eliminate.\n",
        "\n",
        "\n",
        "Trade-off: As you increase model complexity, bias tends to go down (the model can fit more patterns), but variance tends to go up (model may fit noise). Conversely, simpler models have low variance but high bias. The goal is to find a sweet spot where the sum of bias² + variance is minimized (i.e. good performance on both training and unseen data)."
      ],
      "metadata": {
        "id": "uiC5BMo9E9gN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. What are outliers in a dataset, and list three common techniques for\n",
        "handling them.\n",
        "\n",
        "-> An outlier is a data point that significantly differs from other observations in your dataset. It lies unusually far from the rest of the data.\n",
        "\n",
        "Three Common Techniques for Handling Outliers\n",
        "\n",
        "Here are three widely used methods to handle outliers, along with when & how they are used:\n",
        "\n",
        "Removal / Trimming\n",
        "\n",
        "What it is: Simply remove outlier observations from the dataset. Also called trimming.\n",
        "\n",
        "\n",
        "When it's okay: If you are confident that those outliers are errors, or they do not represent anything meaningful (e.g. data entry errors), or they are so extreme that they distort the model.\n",
        "\n",
        "Downsides: Can lose information; if many outliers are removed, data sample may shrink, possibly introducing bias. Also, if outliers are real (not errors), removing them may hide important phenomena.\n",
        "\n",
        "Capping / Winsorization\n",
        "\n",
        "What it is: Instead of removing outliers, you set them to a threshold value (a specified percentile). For example, values above the 95th percentile are set equal to the 95th percentile (and similarly for the low end). That’s called Winsorizing.\n",
        "\n",
        "\n",
        "When it is useful: When you want to limit the effect of extreme values but not completely discard those data points. This preserves sample size, reduces the influence of outliers, but still acknowledges they exist.\n",
        "\n",
        "Considerations: The choice of thresholds is arbitrary; capping reduces variance artificially; may distort relationships if many values are capped.\n",
        "\n",
        "Transformations\n",
        "\n",
        "What it is: Apply a mathematical transformation to reduce the effect of outliers (e.g. log transform, square root, Box-Cox, etc.). These compress large values and expand small values, thus “pulling in” extremes.\n",
        "\n",
        "When to use: Especially when data is skewed and has heavy tails. If the outliers are natural and you don’t want to remove them but need to stabilize variance or improve model assumptions.\n",
        "\n",
        "Trade-offs: Transformed data may be harder to interpret; sometimes transformation doesn’t fully correct issues; must be chosen carefully so model assumptions are better satisfied."
      ],
      "metadata": {
        "id": "iOzWcQj3F8hX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. Explain the process of handling missing values and mention one\n",
        "imputation technique for numerical and one for categorical data.\n",
        "\n",
        "-> Process of Handling Missing Values\n",
        "\n",
        "When working with a dataset that has missing values, you typically follow a procedure to deal with them in a systematic, defensible way. A good process often includes these steps:\n",
        "\n",
        "Detect & quantify missingness\n",
        "\n",
        "Check which features (columns) have missing values, and how many (percentage, counts).\n",
        "\n",
        "Look at patterns of missingness — is missingness more in certain rows, or correlated with other variables, etc.\n",
        "\n",
        "Understand the type / mechanism of missingness\n",
        "\n",
        "MCAR (Missing Completely At Random): Missingness has no relation to observed or unobserved data.\n",
        "\n",
        "MAR (Missing At Random): Missingness is related to the observed data.\n",
        "\n",
        "MNAR (Missing Not At Random): Missingness depends on the missing values themselves (or unobserved variables).\n",
        "This understanding helps choose how safe or risky different treatments are.\n",
        "\n",
        "\n",
        "Decide on strategy based on how much missingness there is, which variables are missing, importance of those variables, and how sensitive your downstream model is to missing data.\n",
        "\n",
        "Common overall strategies include:\n",
        "\n",
        "Deletion: dropping rows (or sometimes columns) with missing values.\n",
        "\n",
        "Imputation: filling in missing values with estimates.\n",
        "\n",
        "Using models that tolerate / handle missing data intrinsically.\n",
        "\n",
        "Flagging missingness: adding indicator features showing that a value was missing, if that itself may carry information.\n",
        "\n",
        "Apply imputation or transformation (if imputation chosen), making sure to do it properly (often separately for training and test sets, so as not to leak information).\n",
        "\n",
        "Evaluate impact\n",
        "\n",
        "Check how the imputation (or deletion) has changed data distributions.\n",
        "\n",
        "Assess whether the downstream model’s performance improves or degrades.\n",
        "\n",
        "Possibly compare multiple imputation strategies.\n",
        "\n",
        "Document / justify your choice: Why did you choose mean vs median vs mode vs model-based imputation, etc. Be aware of biases introduced.\n",
        "\n",
        "One Imputation Technique for Numerical Data\n",
        "\n",
        "Mean Imputation\n",
        "\n",
        "What it is: Replace missing values in a numerical feature with the mean (average) of the non-missing values in that feature.\n",
        "\n",
        "When it's suitable: When the missingness is small amount (not too many missing), and the distribution is relatively symmetric (not heavily skewed), and simple modelling suffices.\n",
        "\n",
        "Pros: Very simple, fast, easy to implement.\n",
        "\n",
        "Cons: Distorts variance (tends to reduce it), may bias estimates, doesn’t use relationships from other features. If there are outliers, mean can itself be misleading.\n",
        "\n",
        "Example: Suppose in a dataset of house prices, the “Lot Size” feature has some missing values. You compute the mean lot size of all houses with known lot size and fill in that mean value for the missing ones.\n",
        "\n",
        "One Imputation Technique for Categorical Data\n",
        "\n",
        "Mode (Most Frequent Value) Imputation\n",
        "\n",
        "What it is: Replace missing values in a categorical feature by the most frequent category (“mode”) in that feature.\n",
        "\n",
        "When it's suitable: When you have some missingness, the most frequent category is meaningful and fairly dominant, and you believe missing values are “like” the majority.\n",
        "\n",
        "Pros: Simple, preserves categorical nature, cheap to compute.\n",
        "\n",
        "Cons: Can lead to over-representing the dominant category, bias, reduce variability, misrepresent underlying distribution especially if missing values are not random.\n",
        "\n",
        "Example: Suppose you have a dataset of customers, with a column “Payment Method” (Credit Card, Debit, Cash). If many entries are missing, you find that “Credit Card” is the most common among existing ones. You fill missing “Payment Method” with “Credit Card.”"
      ],
      "metadata": {
        "id": "zm1eanAAGQAs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. Write a Python program that:\n",
        "● Creates a synthetic imbalanced dataset with make_classification() from\n",
        "sklearn.datasets.\n",
        "● Prints the class distribution"
      ],
      "metadata": {
        "id": "piB1TKneGxys"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import make_classification\n",
        "from collections import Counter\n",
        "\n",
        "def create_imbalanced_dataset(n_samples=1000, imbalance_ratio=0.05, random_state=42):\n",
        "    \"\"\"\n",
        "    Creates an imbalanced binary classification dataset.\n",
        "\n",
        "    Parameters:\n",
        "        n_samples (int): total number of examples\n",
        "        imbalance_ratio (float): proportion of samples in the minority class\n",
        "        random_state (int): seed for reproducibility\n",
        "\n",
        "    Returns:\n",
        "        X, y (arrays): features and labels\n",
        "    \"\"\"\n",
        "    # weights: specify the distribution of classes.\n",
        "    # If imbalance_ratio=0.05, that means ~5% will be in class 1, ~95% in class 0.\n",
        "    weights = [1 - imbalance_ratio, imbalance_ratio]\n",
        "\n",
        "    X, y = make_classification(\n",
        "        n_samples=n_samples,\n",
        "        n_features=20,          # number of features; you can change as needed\n",
        "        n_informative=2,         # number of informative features\n",
        "        n_redundant=2,            # redundant features\n",
        "        n_repeated=0,\n",
        "        n_classes=2,\n",
        "        weights=weights,\n",
        "        flip_y=0,\n",
        "        class_sep=1.0,\n",
        "        random_state=random_state\n",
        "    )\n",
        "\n",
        "    return X, y\n",
        "\n",
        "def print_class_distribution(y):\n",
        "    \"\"\"Prints how many samples in each class.\"\"\"\n",
        "    counter = Counter(y)\n",
        "    for cls, count in counter.items():\n",
        "        print(f\"Class {cls}: {count} samples\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    X, y = create_imbalanced_dataset(n_samples=1000, imbalance_ratio=0.05, random_state=0)\n",
        "    print(\"Class distribution in generated dataset:\")\n",
        "    print_class_distribution(y)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "emdS1GchEb75",
        "outputId": "b1d4c936-0805-4b75-ceec-72df48442a8d"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class distribution in generated dataset:\n",
            "Class 0: 950 samples\n",
            "Class 1: 50 samples\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "7. Implement one-hot encoding using pandas for the following list of colors:\n",
        "['Red', 'Green', 'Blue', 'Green', 'Red']. Print the resulting dataframe."
      ],
      "metadata": {
        "id": "vSBubjWQHCa2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Original list\n",
        "colors = ['Red', 'Green', 'Blue', 'Green', 'Red']\n",
        "\n",
        "# Create a DataFrame\n",
        "df = pd.DataFrame({'Color': colors})\n",
        "\n",
        "# One-hot encode using pandas.get_dummies()\n",
        "df_encoded = pd.get_dummies(df, columns=['Color'], prefix='Color', dtype=int)\n",
        "\n",
        "print(df_encoded)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Pz_V7sDHAD8",
        "outputId": "5c21d082-d90a-488f-aa76-eee446597d88"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Color_Blue  Color_Green  Color_Red\n",
            "0           0            0          1\n",
            "1           0            1          0\n",
            "2           1            0          0\n",
            "3           0            1          0\n",
            "4           0            0          1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "8. Write a Python script to:\n",
        "● Generate 1000 samples from a normal distribution.\n",
        "● Introduce 50 random missing values.\n",
        "● Fill missing values with the column mean.\n",
        "● Plot a histogram before and after imputation.\n"
      ],
      "metadata": {
        "id": "QG8ro0jSHReM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# For reproducibility\n",
        "np.random.seed(0)\n",
        "\n",
        "# 1. Generate 1000 samples from a normal distribution\n",
        "data = np.random.randn(1000)  # mean 0, standard deviation 1\n",
        "\n",
        "# Put into a DataFrame (for easier handling of missingness, etc.)\n",
        "df = pd.DataFrame({'value': data})\n",
        "\n",
        "# 2. Introduce 50 random missing values\n",
        "# Choose 50 unique indices at random\n",
        "missing_indices = np.random.choice(df.index, size=50, replace=False)\n",
        "df.loc[missing_indices, 'value'] = np.nan\n",
        "\n",
        "# 3. Fill missing values with the column mean (imputation)\n",
        "mean_value = df['value'].mean(skipna=True)\n",
        "df_imputed = df.copy()\n",
        "df_imputed['value'] = df_imputed['value'].fillna(mean_value)\n",
        "\n",
        "# 4. Plot histograms before and after imputation\n",
        "\n",
        "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(12, 5))\n",
        "\n",
        "# Histogram before imputation (with missing values)\n",
        "axes[0].hist(df['value'].dropna(), bins=30, color='skyblue', edgecolor='black')\n",
        "axes[0].set_title('Histogram Before Imputation')\n",
        "axes[0].set_xlabel('Value')\n",
        "axes[0].set_ylabel('Frequency')\n",
        "\n",
        "# Histogram after imputation\n",
        "axes[1].hist(df_imputed['value'], bins=30, color='salmon', edgecolor='black')\n",
        "axes[1].set_title('Histogram After Imputation (mean fill)')\n",
        "axes[1].set_xlabel('Value')\n",
        "axes[1].set_ylabel('Frequency')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 507
        },
        "id": "nRDsUPsdHNH9",
        "outputId": "facf0181-7eb0-4637-b077-524c28c024a4"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x500 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "9. Implement Min-Max scaling on the following list of numbers [2, 5, 10, 15,\n",
        "20] using sklearn.preprocessing.MinMaxScaler. Print the scaled array.\n"
      ],
      "metadata": {
        "id": "mgqD0fR3HbA0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import numpy as np\n",
        "\n",
        "# Original data\n",
        "data = np.array([2, 5, 10, 15, 20]).reshape(-1, 1)  # reshape to (n_samples, n_features)\n",
        "\n",
        "# Initialize scaler\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "\n",
        "# Fit & transform\n",
        "scaled_data = scaler.fit_transform(data)\n",
        "\n",
        "print(\"Original data:\", data.flatten())\n",
        "print(\"Scaled data (0-1 range):\", scaled_data.flatten())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8e2ghSPEHWtF",
        "outputId": "d9fbc312-8f99-481d-f80b-9b120f83a5cf"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original data: [ 2  5 10 15 20]\n",
            "Scaled data (0-1 range): [0.         0.16666667 0.44444444 0.72222222 1.        ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "10. You are working as a data scientist for a retail company. You receive a customer\n",
        "transaction dataset that contains:\n",
        "● Missing ages,\n",
        "● Outliers in transaction amount,\n",
        "● A highly imbalanced target (fraud vs. non-fraud),\n",
        "● Categorical variables like payment method.\n",
        "Explain the step-by-step data preparation plan you’d follow before training a machine learning\n",
        "model. Include how you’d address missing data, outliers, imbalance, and encoding."
      ],
      "metadata": {
        "id": "SwR4Od_YHkwT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "-> Step 1: Handling Missing Data\n",
        "Approach:\n",
        "\n",
        "Numerical Columns (e.g., Age): Impute missing values using the mean or median to maintain distribution integrity.\n",
        "\n",
        "Categorical Columns (e.g., Payment Method): Impute missing values with the mode or introduce a new category like 'Unknown'."
      ],
      "metadata": {
        "id": "JefX1-rhH67F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "# Sample data\n",
        "data = {'age': [25, None, 30, 35, None],\n",
        "        'payment_method': ['Credit Card', 'Debit Card', None, 'Credit Card', 'Debit Card'],\n",
        "        'amount': [100, 200, 150, 300, 250],\n",
        "        'fraud': [0, 1, 0, 0, 1]}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Impute missing numerical values with mean\n",
        "num_imputer = SimpleImputer(strategy='mean')\n",
        "df['age'] = num_imputer.fit_transform(df[['age']])\n",
        "\n",
        "# Impute missing categorical values with mode\n",
        "cat_imputer = SimpleImputer(strategy='most_frequent')\n",
        "df['payment_method'] = cat_imputer.fit_transform(df[['payment_method']])\n",
        "\n",
        "print(\"Data after handling missing values:\")\n",
        "print(df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "qi94b3dlHjcZ",
        "outputId": "2e3d8579-044f-4524-d49c-a4adecb217c2"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "2",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-608476629.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m# Impute missing categorical values with mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mcat_imputer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSimpleImputer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'most_frequent'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'payment_method'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcat_imputer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'payment_method'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Data after handling missing values:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   4309\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4310\u001b[0m             \u001b[0;31m# set column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4311\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_item\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4313\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_setitem_slice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mslice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_set_item\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   4522\u001b[0m         \u001b[0mensure\u001b[0m \u001b[0mhomogeneity\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4523\u001b[0m         \"\"\"\n\u001b[0;32m-> 4524\u001b[0;31m         \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrefs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sanitize_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4525\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4526\u001b[0m         if (\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_sanitize_column\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m   5265\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_list_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5266\u001b[0m             \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequire_length_match\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5267\u001b[0;31m         \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msanitize_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5268\u001b[0m         if (\n\u001b[1;32m   5269\u001b[0m             \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIndex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/construction.py\u001b[0m in \u001b[0;36msanitize_array\u001b[0;34m(data, index, dtype, copy, allow_2d)\u001b[0m\n\u001b[1;32m    604\u001b[0m             \u001b[0msubarr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    605\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 606\u001b[0;31m                 \u001b[0msubarr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmaybe_infer_to_datetimelike\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    607\u001b[0m                 if (\n\u001b[1;32m    608\u001b[0m                     \u001b[0mobject_index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/dtypes/cast.py\u001b[0m in \u001b[0;36mmaybe_infer_to_datetimelike\u001b[0;34m(value)\u001b[0m\n\u001b[1;32m   1180\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1181\u001b[0m         \u001b[0;31m# Caller is responsible\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1182\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pragma: no cover\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1184\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: 2"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 2: Addressing Outliers in Transaction Amount\n",
        "Approach:\n",
        "\n",
        "Detection: Use Z-scores or IQR (Interquartile Range) to identify outliers.\n",
        "\n",
        "Handling: Depending on business context:\n",
        "\n",
        "Remove: If outliers are errors.\n",
        "\n",
        "Cap: Apply Winsorization to limit extreme values.\n",
        "\n",
        "Transform: Use logarithmic scaling to reduce skewness."
      ],
      "metadata": {
        "id": "mjWXW4NPIAVE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy import stats\n",
        "\n",
        "# Calculate Z-scores\n",
        "z_scores = np.abs(stats.zscore(df['amount']))\n",
        "\n",
        "# Define a threshold\n",
        "threshold = 3\n",
        "\n",
        "# Identify outliers\n",
        "outliers = np.where(z_scores > threshold)\n",
        "\n",
        "# Handle outliers (e.g., cap them at a certain value)\n",
        "df['amount'] = np.where(df['amount'] > 300, 300, df['amount'])\n",
        "\n",
        "print(\"\\nData after handling outliers:\")\n",
        "print(df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1kRd2IMsIKCO",
        "outputId": "9f30bc52-0408-4525-eb47-d9e9f14f7d80"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Data after handling outliers:\n",
            "    age payment_method  amount  fraud\n",
            "0  25.0    Credit Card     100      0\n",
            "1  30.0     Debit Card     200      1\n",
            "2  30.0           None     150      0\n",
            "3  35.0    Credit Card     300      0\n",
            "4  30.0     Debit Card     250      1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 3: Handling Class Imbalance (Fraud vs. Non-Fraud)\n",
        "Approach:\n",
        "\n",
        "Resampling Techniques:\n",
        "\n",
        "Oversampling: Use SMOTE (Synthetic Minority Over-sampling Technique) to generate synthetic samples for the minority class.\n",
        "\n",
        "Undersampling: Randomly reduce the majority class samples.\n",
        "\n",
        "Algorithm-Level Solutions: Utilize models that handle class imbalance internally, such as Balanced Random Forests or XGBoost with scale_pos_weight."
      ],
      "metadata": {
        "id": "2IGrTT66IMZ0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.over_sampling import SMOTE\n",
        "from collections import Counter\n",
        "\n",
        "# Sample data\n",
        "X = df[['age', 'amount']]  # Features\n",
        "y = df['fraud']            # Target\n",
        "\n",
        "# Apply SMOTE\n",
        "smote = SMOTE(random_state=42)\n",
        "X_res, y_res = smote.fit_resample(X, y)\n",
        "\n",
        "print(\"\\nClass distribution after SMOTE:\")\n",
        "print(Counter(y_res))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "jd4Y97-wH-zr",
        "outputId": "cbf2b25d-a55a-4225-87c8-fb8c5f2919cb"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Expected n_neighbors <= n_samples_fit, but n_neighbors = 6, n_samples_fit = 2, n_samples = 2",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1505466146.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Apply SMOTE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0msmote\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSMOTE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mX_res\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_res\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msmote\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_resample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nClass distribution after SMOTE:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/imblearn/base.py\u001b[0m in \u001b[0;36mfit_resample\u001b[0;34m(self, X, y, **params)\u001b[0m\n\u001b[1;32m    200\u001b[0m             \u001b[0mThe\u001b[0m \u001b[0mcorresponding\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0mof\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mX_resampled\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m         \"\"\"\n\u001b[0;32m--> 202\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_resample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_more_tags\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1387\u001b[0m                 )\n\u001b[1;32m   1388\u001b[0m             ):\n\u001b[0;32m-> 1389\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfit_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1391\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/imblearn/base.py\u001b[0m in \u001b[0;36mfit_resample\u001b[0;34m(self, X, y, **params)\u001b[0m\n\u001b[1;32m    103\u001b[0m         )\n\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_resample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m         y_ = (\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/imblearn/over_sampling/_smote/base.py\u001b[0m in \u001b[0;36m_fit_resample\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    357\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn_k_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_class\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 359\u001b[0;31m             \u001b[0mnns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn_k_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkneighbors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_class\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_distance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    360\u001b[0m             X_new, y_new = self._make_samples(\n\u001b[1;32m    361\u001b[0m                 \u001b[0mX_class\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_sample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_class\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/neighbors/_base.py\u001b[0m in \u001b[0;36mkneighbors\u001b[0;34m(self, X, n_neighbors, return_distance)\u001b[0m\n\u001b[1;32m    852\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    853\u001b[0m                 \u001b[0minequality_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"n_neighbors <= n_samples_fit\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 854\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m    855\u001b[0m                 \u001b[0;34mf\"Expected {inequality_str}, but \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    856\u001b[0m                 \u001b[0;34mf\"n_neighbors = {n_neighbors}, n_samples_fit = {n_samples_fit}, \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Expected n_neighbors <= n_samples_fit, but n_neighbors = 6, n_samples_fit = 2, n_samples = 2"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 4: Encoding Categorical Variables (e.g., Payment Method)\n",
        "Approach:\n",
        "\n",
        "One-Hot Encoding: For nominal variables like 'payment_method', create binary columns for each category.\n",
        "\n",
        "Label Encoding: For ordinal variables, assign integer labels to categories."
      ],
      "metadata": {
        "id": "u9lYe2GDIT0f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# One-Hot Encoding for 'payment_method'\n",
        "df_encoded = pd.get_dummies(df, columns=['payment_method'], drop_first=True)\n",
        "\n",
        "print(\"\\nData after One-Hot Encoding:\")\n",
        "print(df_encoded)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AqrRGMNYIQjq",
        "outputId": "995e2891-ce62-4478-a02c-025af1133139"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Data after One-Hot Encoding:\n",
            "    age  amount  fraud  payment_method_Debit Card\n",
            "0  25.0     100      0                      False\n",
            "1  30.0     200      1                       True\n",
            "2  30.0     150      0                      False\n",
            "3  35.0     300      0                      False\n",
            "4  30.0     250      1                       True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 5: Scaling Numerical Features\n",
        "Approach:\n",
        "\n",
        "Standardization: Scale features to have zero mean and unit variance using StandardScaler.\n",
        "\n",
        "Normalization: Scale features to a [0, 1] range using MinMaxScaler."
      ],
      "metadata": {
        "id": "cdNfsrarIWiG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "\n",
        "# Standardization\n",
        "scaler = StandardScaler()\n",
        "df_encoded[['age', 'amount']] = scaler.fit_transform(df_encoded[['age', 'amount']])\n",
        "\n",
        "# Alternatively, Min-Max Scaling\n",
        "# scaler = MinMaxScaler()\n",
        "# df_encoded[['age', 'amount']] = scaler.fit_transform(df_encoded[['age', 'amount']])\n",
        "\n",
        "print(\"\\nData after scaling:\")\n",
        "print(df_encoded)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9PB3K-f7IVgz",
        "outputId": "b47c2923-0125-4ee3-815d-d264402a287d"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Data after scaling:\n",
            "        age    amount  fraud  payment_method_Debit Card\n",
            "0 -1.581139 -1.414214      0                      False\n",
            "1  0.000000  0.000000      1                       True\n",
            "2  0.000000 -0.707107      0                      False\n",
            "3  1.581139  1.414214      0                      False\n",
            "4  0.000000  0.707107      1                       True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DmCxusIIIaVS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}